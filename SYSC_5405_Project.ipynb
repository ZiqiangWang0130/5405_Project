{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LVxB0138IHhP"
   },
   "outputs": [],
   "source": [
    "#!pip install d2l\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from d2l import tensorflow as d2l\n",
    "\n",
    "#data = pd.read_csv('train_data.csv') # load original dataset \n",
    "\n",
    "# split dataset into 75/25 train test split \n",
    "# train, test = sklearn.model_selection.train_test_split(data, test_size=.25, random_state=42, shuffle=True, stratify=data['Label'])\n",
    "# train.to_csv('split_train_data.csv', index = False) # save train data for future use \n",
    "# test.to_csv('split_test_data.csv', index = False) # save test data for future use \n",
    "\n",
    "train = pd.read_csv('split_train_data.csv')\n",
    "test = pd.read_csv('split_test_data.csv')\n",
    "# descriptive info \n",
    "shape = train.shape # shape of the training set \n",
    "column_names = train.columns # names of the columns \n",
    "nunique = train.nunique(axis = 0) # number of unique entries in each column \n",
    "describe = train.describe().apply(lambda s: s.apply(lambda x: format(x, 'f')))\n",
    "\n",
    "# varriable relationships \n",
    "corr = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "STgO4U8vRipp",
    "outputId": "48b26177-0afa-44ba-d3d8-cc05949a9f93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G26</th>\n",
       "      <th>G26_Target Sequence_in_SMILES_perc</th>\n",
       "      <th>G26_SMILES_in_Target Sequence_perc</th>\n",
       "      <th>G26_ARRO</th>\n",
       "      <th>G26_SMILES_base</th>\n",
       "      <th>G26_SMILES_base_perc</th>\n",
       "      <th>G26_Target Sequence_base</th>\n",
       "      <th>G26_Target Sequence_base_perc</th>\n",
       "      <th>G26_fdp_SMILES_base</th>\n",
       "      <th>G26_fdp_Target Sequence_base</th>\n",
       "      <th>...</th>\n",
       "      <th>G10_Target Sequence_base</th>\n",
       "      <th>G10_Target Sequence_base_perc</th>\n",
       "      <th>G10_fdp_SMILES_base</th>\n",
       "      <th>G10_fdp_Target Sequence_base</th>\n",
       "      <th>G10_fd_SMILES_base</th>\n",
       "      <th>G10_fd_Target Sequence_base</th>\n",
       "      <th>G10_std_SMILES_dist</th>\n",
       "      <th>G10_std_Target Sequence_dist</th>\n",
       "      <th>KIBA</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.658644</td>\n",
       "      <td>-0.633055</td>\n",
       "      <td>0.169460</td>\n",
       "      <td>0.317016</td>\n",
       "      <td>0.046799</td>\n",
       "      <td>0.468876</td>\n",
       "      <td>0.073782</td>\n",
       "      <td>0.658092</td>\n",
       "      <td>0.628796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435566</td>\n",
       "      <td>-0.024579</td>\n",
       "      <td>0.352305</td>\n",
       "      <td>0.114382</td>\n",
       "      <td>0.427409</td>\n",
       "      <td>0.159265</td>\n",
       "      <td>0.430174</td>\n",
       "      <td>0.111489</td>\n",
       "      <td>0.201958</td>\n",
       "      <td>0.152989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G26_Target Sequence_in_SMILES_perc</th>\n",
       "      <td>-0.658644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.445067</td>\n",
       "      <td>-0.043587</td>\n",
       "      <td>0.066026</td>\n",
       "      <td>-0.089851</td>\n",
       "      <td>-0.519167</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>-0.999657</td>\n",
       "      <td>-0.434097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.468423</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>-0.457180</td>\n",
       "      <td>-0.006301</td>\n",
       "      <td>-0.460008</td>\n",
       "      <td>-0.062057</td>\n",
       "      <td>-0.461446</td>\n",
       "      <td>-0.009689</td>\n",
       "      <td>-0.138569</td>\n",
       "      <td>-0.101433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G26_SMILES_in_Target Sequence_perc</th>\n",
       "      <td>-0.633055</td>\n",
       "      <td>0.445067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.060159</td>\n",
       "      <td>-0.351306</td>\n",
       "      <td>-0.052088</td>\n",
       "      <td>0.096178</td>\n",
       "      <td>-0.092368</td>\n",
       "      <td>-0.445232</td>\n",
       "      <td>-0.989815</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203279</td>\n",
       "      <td>-0.011771</td>\n",
       "      <td>-0.138484</td>\n",
       "      <td>-0.165737</td>\n",
       "      <td>-0.197774</td>\n",
       "      <td>-0.185393</td>\n",
       "      <td>-0.200663</td>\n",
       "      <td>-0.163143</td>\n",
       "      <td>-0.120547</td>\n",
       "      <td>-0.096686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G26_ARRO</th>\n",
       "      <td>0.169460</td>\n",
       "      <td>-0.043587</td>\n",
       "      <td>-0.060159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017315</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>0.028395</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>0.043416</td>\n",
       "      <td>0.059851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.014627</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.024407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G26_SMILES_base</th>\n",
       "      <td>0.317016</td>\n",
       "      <td>0.066026</td>\n",
       "      <td>-0.351306</td>\n",
       "      <td>0.017315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.124027</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>-0.024344</td>\n",
       "      <td>-0.069111</td>\n",
       "      <td>0.339608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015930</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>-0.005021</td>\n",
       "      <td>0.290070</td>\n",
       "      <td>-0.018700</td>\n",
       "      <td>0.271482</td>\n",
       "      <td>-0.016655</td>\n",
       "      <td>0.273123</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>0.076241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G10_fd_Target Sequence_base</th>\n",
       "      <td>0.159265</td>\n",
       "      <td>-0.062057</td>\n",
       "      <td>-0.185393</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.271482</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.056342</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>0.061979</td>\n",
       "      <td>0.181444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088498</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.174753</td>\n",
       "      <td>0.947796</td>\n",
       "      <td>0.148408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151270</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>-0.017994</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G10_std_SMILES_dist</th>\n",
       "      <td>0.430174</td>\n",
       "      <td>-0.461446</td>\n",
       "      <td>-0.200663</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>-0.016655</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>0.470985</td>\n",
       "      <td>0.200450</td>\n",
       "      <td>0.460587</td>\n",
       "      <td>0.224628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983837</td>\n",
       "      <td>-0.093897</td>\n",
       "      <td>0.790549</td>\n",
       "      <td>0.026387</td>\n",
       "      <td>0.998637</td>\n",
       "      <td>0.151270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044706</td>\n",
       "      <td>0.210049</td>\n",
       "      <td>0.143338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G10_std_Target Sequence_dist</th>\n",
       "      <td>0.111489</td>\n",
       "      <td>-0.009689</td>\n",
       "      <td>-0.163143</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.273123</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>-0.017986</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.156756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019936</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.086213</td>\n",
       "      <td>0.954489</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>0.044706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041591</td>\n",
       "      <td>-0.016061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIBA</th>\n",
       "      <td>0.201958</td>\n",
       "      <td>-0.138569</td>\n",
       "      <td>-0.120547</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>-0.008088</td>\n",
       "      <td>0.084013</td>\n",
       "      <td>0.065451</td>\n",
       "      <td>0.137980</td>\n",
       "      <td>0.127085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213941</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.193341</td>\n",
       "      <td>-0.048125</td>\n",
       "      <td>0.210583</td>\n",
       "      <td>-0.017994</td>\n",
       "      <td>0.210049</td>\n",
       "      <td>-0.041591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.763603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <td>0.152989</td>\n",
       "      <td>-0.101433</td>\n",
       "      <td>-0.096686</td>\n",
       "      <td>0.024407</td>\n",
       "      <td>0.076241</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>0.082866</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>0.101357</td>\n",
       "      <td>0.096723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144950</td>\n",
       "      <td>-0.022376</td>\n",
       "      <td>0.121367</td>\n",
       "      <td>-0.021633</td>\n",
       "      <td>0.144011</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.143338</td>\n",
       "      <td>-0.016061</td>\n",
       "      <td>0.763603</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         G26  \\\n",
       "G26                                 1.000000   \n",
       "G26_Target Sequence_in_SMILES_perc -0.658644   \n",
       "G26_SMILES_in_Target Sequence_perc -0.633055   \n",
       "G26_ARRO                            0.169460   \n",
       "G26_SMILES_base                     0.317016   \n",
       "...                                      ...   \n",
       "G10_fd_Target Sequence_base         0.159265   \n",
       "G10_std_SMILES_dist                 0.430174   \n",
       "G10_std_Target Sequence_dist        0.111489   \n",
       "KIBA                                0.201958   \n",
       "Label                               0.152989   \n",
       "\n",
       "                                    G26_Target Sequence_in_SMILES_perc  \\\n",
       "G26                                                          -0.658644   \n",
       "G26_Target Sequence_in_SMILES_perc                            1.000000   \n",
       "G26_SMILES_in_Target Sequence_perc                            0.445067   \n",
       "G26_ARRO                                                     -0.043587   \n",
       "G26_SMILES_base                                               0.066026   \n",
       "...                                                                ...   \n",
       "G10_fd_Target Sequence_base                                  -0.062057   \n",
       "G10_std_SMILES_dist                                          -0.461446   \n",
       "G10_std_Target Sequence_dist                                 -0.009689   \n",
       "KIBA                                                         -0.138569   \n",
       "Label                                                        -0.101433   \n",
       "\n",
       "                                    G26_SMILES_in_Target Sequence_perc  \\\n",
       "G26                                                          -0.633055   \n",
       "G26_Target Sequence_in_SMILES_perc                            0.445067   \n",
       "G26_SMILES_in_Target Sequence_perc                            1.000000   \n",
       "G26_ARRO                                                     -0.060159   \n",
       "G26_SMILES_base                                              -0.351306   \n",
       "...                                                                ...   \n",
       "G10_fd_Target Sequence_base                                  -0.185393   \n",
       "G10_std_SMILES_dist                                          -0.200663   \n",
       "G10_std_Target Sequence_dist                                 -0.163143   \n",
       "KIBA                                                         -0.120547   \n",
       "Label                                                        -0.096686   \n",
       "\n",
       "                                    G26_ARRO  G26_SMILES_base  \\\n",
       "G26                                 0.169460         0.317016   \n",
       "G26_Target Sequence_in_SMILES_perc -0.043587         0.066026   \n",
       "G26_SMILES_in_Target Sequence_perc -0.060159        -0.351306   \n",
       "G26_ARRO                            1.000000         0.017315   \n",
       "G26_SMILES_base                     0.017315         1.000000   \n",
       "...                                      ...              ...   \n",
       "G10_fd_Target Sequence_base         0.006812         0.271482   \n",
       "G10_std_SMILES_dist                 0.022396        -0.016655   \n",
       "G10_std_Target Sequence_dist        0.004067         0.273123   \n",
       "KIBA                                0.061611         0.079321   \n",
       "Label                               0.024407         0.076241   \n",
       "\n",
       "                                    G26_SMILES_base_perc  \\\n",
       "G26                                             0.046799   \n",
       "G26_Target Sequence_in_SMILES_perc             -0.089851   \n",
       "G26_SMILES_in_Target Sequence_perc             -0.052088   \n",
       "G26_ARRO                                       -0.002004   \n",
       "G26_SMILES_base                                -0.124027   \n",
       "...                                                  ...   \n",
       "G10_fd_Target Sequence_base                     0.003418   \n",
       "G10_std_SMILES_dist                             0.014829   \n",
       "G10_std_Target Sequence_dist                    0.001927   \n",
       "KIBA                                           -0.008088   \n",
       "Label                                           0.007527   \n",
       "\n",
       "                                    G26_Target Sequence_base  \\\n",
       "G26                                                 0.468876   \n",
       "G26_Target Sequence_in_SMILES_perc                 -0.519167   \n",
       "G26_SMILES_in_Target Sequence_perc                  0.096178   \n",
       "G26_ARRO                                            0.028395   \n",
       "G26_SMILES_base                                     0.014272   \n",
       "...                                                      ...   \n",
       "G10_fd_Target Sequence_base                         0.056342   \n",
       "G10_std_SMILES_dist                                 0.470985   \n",
       "G10_std_Target Sequence_dist                        0.002017   \n",
       "KIBA                                                0.084013   \n",
       "Label                                               0.082866   \n",
       "\n",
       "                                    G26_Target Sequence_base_perc  \\\n",
       "G26                                                      0.073782   \n",
       "G26_Target Sequence_in_SMILES_perc                       0.003909   \n",
       "G26_SMILES_in_Target Sequence_perc                      -0.092368   \n",
       "G26_ARRO                                                 0.007683   \n",
       "G26_SMILES_base                                         -0.024344   \n",
       "...                                                           ...   \n",
       "G10_fd_Target Sequence_base                              0.002712   \n",
       "G10_std_SMILES_dist                                      0.200450   \n",
       "G10_std_Target Sequence_dist                            -0.017986   \n",
       "KIBA                                                     0.065451   \n",
       "Label                                                    0.016079   \n",
       "\n",
       "                                    G26_fdp_SMILES_base  \\\n",
       "G26                                            0.658092   \n",
       "G26_Target Sequence_in_SMILES_perc            -0.999657   \n",
       "G26_SMILES_in_Target Sequence_perc            -0.445232   \n",
       "G26_ARRO                                       0.043416   \n",
       "G26_SMILES_base                               -0.069111   \n",
       "...                                                 ...   \n",
       "G10_fd_Target Sequence_base                    0.061979   \n",
       "G10_std_SMILES_dist                            0.460587   \n",
       "G10_std_Target Sequence_dist                   0.009713   \n",
       "KIBA                                           0.137980   \n",
       "Label                                          0.101357   \n",
       "\n",
       "                                    G26_fdp_Target Sequence_base  ...  \\\n",
       "G26                                                     0.628796  ...   \n",
       "G26_Target Sequence_in_SMILES_perc                     -0.434097  ...   \n",
       "G26_SMILES_in_Target Sequence_perc                     -0.989815  ...   \n",
       "G26_ARRO                                                0.059851  ...   \n",
       "G26_SMILES_base                                         0.339608  ...   \n",
       "...                                                          ...  ...   \n",
       "G10_fd_Target Sequence_base                             0.181444  ...   \n",
       "G10_std_SMILES_dist                                     0.224628  ...   \n",
       "G10_std_Target Sequence_dist                            0.156756  ...   \n",
       "KIBA                                                    0.127085  ...   \n",
       "Label                                                   0.096723  ...   \n",
       "\n",
       "                                    G10_Target Sequence_base  \\\n",
       "G26                                                 0.435566   \n",
       "G26_Target Sequence_in_SMILES_perc                 -0.468423   \n",
       "G26_SMILES_in_Target Sequence_perc                 -0.203279   \n",
       "G26_ARRO                                            0.022727   \n",
       "G26_SMILES_base                                    -0.015930   \n",
       "...                                                      ...   \n",
       "G10_fd_Target Sequence_base                         0.088498   \n",
       "G10_std_SMILES_dist                                 0.983837   \n",
       "G10_std_Target Sequence_dist                       -0.019936   \n",
       "KIBA                                                0.213941   \n",
       "Label                                               0.144950   \n",
       "\n",
       "                                    G10_Target Sequence_base_perc  \\\n",
       "G26                                                     -0.024579   \n",
       "G26_Target Sequence_in_SMILES_perc                       0.034314   \n",
       "G26_SMILES_in_Target Sequence_perc                      -0.011771   \n",
       "G26_ARRO                                                 0.003300   \n",
       "G26_SMILES_base                                          0.004881   \n",
       "...                                                           ...   \n",
       "G10_fd_Target Sequence_base                              0.003774   \n",
       "G10_std_SMILES_dist                                     -0.093897   \n",
       "G10_std_Target Sequence_dist                             0.000643   \n",
       "KIBA                                                     0.002289   \n",
       "Label                                                   -0.022376   \n",
       "\n",
       "                                    G10_fdp_SMILES_base  \\\n",
       "G26                                            0.352305   \n",
       "G26_Target Sequence_in_SMILES_perc            -0.457180   \n",
       "G26_SMILES_in_Target Sequence_perc            -0.138484   \n",
       "G26_ARRO                                       0.014627   \n",
       "G26_SMILES_base                               -0.005021   \n",
       "...                                                 ...   \n",
       "G10_fd_Target Sequence_base                    0.174753   \n",
       "G10_std_SMILES_dist                            0.790549   \n",
       "G10_std_Target Sequence_dist                   0.086213   \n",
       "KIBA                                           0.193341   \n",
       "Label                                          0.121367   \n",
       "\n",
       "                                    G10_fdp_Target Sequence_base  \\\n",
       "G26                                                     0.114382   \n",
       "G26_Target Sequence_in_SMILES_perc                     -0.006301   \n",
       "G26_SMILES_in_Target Sequence_perc                     -0.165737   \n",
       "G26_ARRO                                                0.005133   \n",
       "G26_SMILES_base                                         0.290070   \n",
       "...                                                          ...   \n",
       "G10_fd_Target Sequence_base                             0.947796   \n",
       "G10_std_SMILES_dist                                     0.026387   \n",
       "G10_std_Target Sequence_dist                            0.954489   \n",
       "KIBA                                                   -0.048125   \n",
       "Label                                                  -0.021633   \n",
       "\n",
       "                                    G10_fd_SMILES_base  \\\n",
       "G26                                           0.427409   \n",
       "G26_Target Sequence_in_SMILES_perc           -0.460008   \n",
       "G26_SMILES_in_Target Sequence_perc           -0.197774   \n",
       "G26_ARRO                                      0.022306   \n",
       "G26_SMILES_base                              -0.018700   \n",
       "...                                                ...   \n",
       "G10_fd_Target Sequence_base                   0.148408   \n",
       "G10_std_SMILES_dist                           0.998637   \n",
       "G10_std_Target Sequence_dist                  0.041350   \n",
       "KIBA                                          0.210583   \n",
       "Label                                         0.144011   \n",
       "\n",
       "                                    G10_fd_Target Sequence_base  \\\n",
       "G26                                                    0.159265   \n",
       "G26_Target Sequence_in_SMILES_perc                    -0.062057   \n",
       "G26_SMILES_in_Target Sequence_perc                    -0.185393   \n",
       "G26_ARRO                                               0.006812   \n",
       "G26_SMILES_base                                        0.271482   \n",
       "...                                                         ...   \n",
       "G10_fd_Target Sequence_base                            1.000000   \n",
       "G10_std_SMILES_dist                                    0.151270   \n",
       "G10_std_Target Sequence_dist                           0.992965   \n",
       "KIBA                                                  -0.017994   \n",
       "Label                                                  0.000707   \n",
       "\n",
       "                                    G10_std_SMILES_dist  \\\n",
       "G26                                            0.430174   \n",
       "G26_Target Sequence_in_SMILES_perc            -0.461446   \n",
       "G26_SMILES_in_Target Sequence_perc            -0.200663   \n",
       "G26_ARRO                                       0.022396   \n",
       "G26_SMILES_base                               -0.016655   \n",
       "...                                                 ...   \n",
       "G10_fd_Target Sequence_base                    0.151270   \n",
       "G10_std_SMILES_dist                            1.000000   \n",
       "G10_std_Target Sequence_dist                   0.044706   \n",
       "KIBA                                           0.210049   \n",
       "Label                                          0.143338   \n",
       "\n",
       "                                    G10_std_Target Sequence_dist      KIBA  \\\n",
       "G26                                                     0.111489  0.201958   \n",
       "G26_Target Sequence_in_SMILES_perc                     -0.009689 -0.138569   \n",
       "G26_SMILES_in_Target Sequence_perc                     -0.163143 -0.120547   \n",
       "G26_ARRO                                                0.004067  0.061611   \n",
       "G26_SMILES_base                                         0.273123  0.079321   \n",
       "...                                                          ...       ...   \n",
       "G10_fd_Target Sequence_base                             0.992965 -0.017994   \n",
       "G10_std_SMILES_dist                                     0.044706  0.210049   \n",
       "G10_std_Target Sequence_dist                            1.000000 -0.041591   \n",
       "KIBA                                                   -0.041591  1.000000   \n",
       "Label                                                  -0.016061  0.763603   \n",
       "\n",
       "                                       Label  \n",
       "G26                                 0.152989  \n",
       "G26_Target Sequence_in_SMILES_perc -0.101433  \n",
       "G26_SMILES_in_Target Sequence_perc -0.096686  \n",
       "G26_ARRO                            0.024407  \n",
       "G26_SMILES_base                     0.076241  \n",
       "...                                      ...  \n",
       "G10_fd_Target Sequence_base         0.000707  \n",
       "G10_std_SMILES_dist                 0.143338  \n",
       "G10_std_Target Sequence_dist       -0.016061  \n",
       "KIBA                                0.763603  \n",
       "Label                               1.000000  \n",
       "\n",
       "[338 rows x 338 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dpbay35VRlBH",
    "outputId": "36eaf687-1468-4c3e-e0eb-bc3aadf6ba9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G26', 'G26_Target Sequence_in_SMILES_perc',\n",
       "       'G26_SMILES_in_Target Sequence_perc', 'G26_ARRO', 'G26_SMILES_base',\n",
       "       'G26_SMILES_base_perc', 'G26_Target Sequence_base',\n",
       "       'G26_Target Sequence_base_perc', 'G26_fdp_SMILES_base',\n",
       "       'G26_fdp_Target Sequence_base', 'G26_fd_SMILES_base',\n",
       "       'G26_fd_Target Sequence_base', 'G26_std_SMILES_dist',\n",
       "       'G26_std_Target Sequence_dist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "JN3YFES_UnJ8",
    "outputId": "8dcae529-1b8d-4288-fa49-cc67a9c4d6bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G26</th>\n",
       "      <th>G26_Target Sequence_in_SMILES_perc</th>\n",
       "      <th>G26_SMILES_in_Target Sequence_perc</th>\n",
       "      <th>G26_ARRO</th>\n",
       "      <th>G26_SMILES_base</th>\n",
       "      <th>G26_SMILES_base_perc</th>\n",
       "      <th>G26_Target Sequence_base</th>\n",
       "      <th>G26_Target Sequence_base_perc</th>\n",
       "      <th>G26_fdp_SMILES_base</th>\n",
       "      <th>G26_fdp_Target Sequence_base</th>\n",
       "      <th>G26_fd_SMILES_base</th>\n",
       "      <th>G26_fd_Target Sequence_base</th>\n",
       "      <th>G26_std_SMILES_dist</th>\n",
       "      <th>G26_std_Target Sequence_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.073946</td>\n",
       "      <td>0.954991</td>\n",
       "      <td>0.062554</td>\n",
       "      <td>16.739510</td>\n",
       "      <td>5.522422</td>\n",
       "      <td>0.105597</td>\n",
       "      <td>5.062549</td>\n",
       "      <td>0.098782</td>\n",
       "      <td>-0.849394</td>\n",
       "      <td>0.036227</td>\n",
       "      <td>-0.081210</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>-1.406308</td>\n",
       "      <td>0.281301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.826617</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>60569.338400</td>\n",
       "      <td>5.590014</td>\n",
       "      <td>0.091748</td>\n",
       "      <td>6.158633</td>\n",
       "      <td>0.126360</td>\n",
       "      <td>0.090594</td>\n",
       "      <td>0.112054</td>\n",
       "      <td>0.221216</td>\n",
       "      <td>0.108463</td>\n",
       "      <td>7.526585</td>\n",
       "      <td>2.646602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.177106</td>\n",
       "      <td>0.818811</td>\n",
       "      <td>0.930755</td>\n",
       "      <td>1.312142</td>\n",
       "      <td>5.556566</td>\n",
       "      <td>0.128679</td>\n",
       "      <td>5.564309</td>\n",
       "      <td>0.099924</td>\n",
       "      <td>-0.690133</td>\n",
       "      <td>-0.830831</td>\n",
       "      <td>-0.068290</td>\n",
       "      <td>-0.069587</td>\n",
       "      <td>-0.813822</td>\n",
       "      <td>-1.115077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.179001</td>\n",
       "      <td>0.183497</td>\n",
       "      <td>0.970300</td>\n",
       "      <td>5.616494</td>\n",
       "      <td>5.258327</td>\n",
       "      <td>0.130410</td>\n",
       "      <td>5.683928</td>\n",
       "      <td>0.086053</td>\n",
       "      <td>-0.053087</td>\n",
       "      <td>-0.884247</td>\n",
       "      <td>-0.015086</td>\n",
       "      <td>-0.088834</td>\n",
       "      <td>-0.071465</td>\n",
       "      <td>-2.502975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.822746</td>\n",
       "      <td>0.029429</td>\n",
       "      <td>0.326915</td>\n",
       "      <td>103.942684</td>\n",
       "      <td>5.621003</td>\n",
       "      <td>0.101558</td>\n",
       "      <td>5.896788</td>\n",
       "      <td>0.281712</td>\n",
       "      <td>0.072129</td>\n",
       "      <td>-0.045202</td>\n",
       "      <td>0.035891</td>\n",
       "      <td>-0.012556</td>\n",
       "      <td>1.872736</td>\n",
       "      <td>0.285750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109474</th>\n",
       "      <td>5.706429</td>\n",
       "      <td>0.185805</td>\n",
       "      <td>0.114284</td>\n",
       "      <td>47.093032</td>\n",
       "      <td>5.747547</td>\n",
       "      <td>0.107905</td>\n",
       "      <td>5.331223</td>\n",
       "      <td>0.334530</td>\n",
       "      <td>-0.077900</td>\n",
       "      <td>0.220246</td>\n",
       "      <td>-0.007154</td>\n",
       "      <td>0.070379</td>\n",
       "      <td>0.495341</td>\n",
       "      <td>1.372400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109475</th>\n",
       "      <td>5.091452</td>\n",
       "      <td>0.922677</td>\n",
       "      <td>0.950718</td>\n",
       "      <td>1.139983</td>\n",
       "      <td>5.456824</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>5.444070</td>\n",
       "      <td>0.204634</td>\n",
       "      <td>-0.801500</td>\n",
       "      <td>-0.746084</td>\n",
       "      <td>-0.066957</td>\n",
       "      <td>-0.064771</td>\n",
       "      <td>-0.722769</td>\n",
       "      <td>-1.269441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109476</th>\n",
       "      <td>6.546598</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.045692</td>\n",
       "      <td>1354.569388</td>\n",
       "      <td>5.250993</td>\n",
       "      <td>0.129833</td>\n",
       "      <td>6.357718</td>\n",
       "      <td>0.109280</td>\n",
       "      <td>0.113676</td>\n",
       "      <td>0.063588</td>\n",
       "      <td>0.246735</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>4.253889</td>\n",
       "      <td>1.786510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109477</th>\n",
       "      <td>5.049065</td>\n",
       "      <td>0.941720</td>\n",
       "      <td>0.965568</td>\n",
       "      <td>1.099754</td>\n",
       "      <td>5.300778</td>\n",
       "      <td>0.118292</td>\n",
       "      <td>5.390484</td>\n",
       "      <td>0.150946</td>\n",
       "      <td>-0.823428</td>\n",
       "      <td>-0.814621</td>\n",
       "      <td>-0.047486</td>\n",
       "      <td>-0.063337</td>\n",
       "      <td>-0.905470</td>\n",
       "      <td>-1.163646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109478</th>\n",
       "      <td>5.041841</td>\n",
       "      <td>0.635314</td>\n",
       "      <td>0.997824</td>\n",
       "      <td>1.577456</td>\n",
       "      <td>5.088853</td>\n",
       "      <td>0.102712</td>\n",
       "      <td>5.998127</td>\n",
       "      <td>0.105744</td>\n",
       "      <td>-0.532602</td>\n",
       "      <td>-0.892080</td>\n",
       "      <td>-0.009238</td>\n",
       "      <td>-0.159431</td>\n",
       "      <td>-0.199843</td>\n",
       "      <td>-2.234073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109479 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             G26  G26_Target Sequence_in_SMILES_perc  \\\n",
       "0       5.073946                            0.954991   \n",
       "1       6.826617                            0.001154   \n",
       "2       5.177106                            0.818811   \n",
       "3       5.179001                            0.183497   \n",
       "4       5.822746                            0.029429   \n",
       "...          ...                                 ...   \n",
       "109474  5.706429                            0.185805   \n",
       "109475  5.091452                            0.922677   \n",
       "109476  6.546598                            0.016157   \n",
       "109477  5.049065                            0.941720   \n",
       "109478  5.041841                            0.635314   \n",
       "\n",
       "        G26_SMILES_in_Target Sequence_perc      G26_ARRO  G26_SMILES_base  \\\n",
       "0                                 0.062554     16.739510         5.522422   \n",
       "1                                 0.014306  60569.338400         5.590014   \n",
       "2                                 0.930755      1.312142         5.556566   \n",
       "3                                 0.970300      5.616494         5.258327   \n",
       "4                                 0.326915    103.942684         5.621003   \n",
       "...                                    ...           ...              ...   \n",
       "109474                            0.114284     47.093032         5.747547   \n",
       "109475                            0.950718      1.139983         5.456824   \n",
       "109476                            0.045692   1354.569388         5.250993   \n",
       "109477                            0.965568      1.099754         5.300778   \n",
       "109478                            0.997824      1.577456         5.088853   \n",
       "\n",
       "        G26_SMILES_base_perc  G26_Target Sequence_base  \\\n",
       "0                   0.105597                  5.062549   \n",
       "1                   0.091748                  6.158633   \n",
       "2                   0.128679                  5.564309   \n",
       "3                   0.130410                  5.683928   \n",
       "4                   0.101558                  5.896788   \n",
       "...                      ...                       ...   \n",
       "109474              0.107905                  5.331223   \n",
       "109475              0.121177                  5.444070   \n",
       "109476              0.129833                  6.357718   \n",
       "109477              0.118292                  5.390484   \n",
       "109478              0.102712                  5.998127   \n",
       "\n",
       "        G26_Target Sequence_base_perc  G26_fdp_SMILES_base  \\\n",
       "0                            0.098782            -0.849394   \n",
       "1                            0.126360             0.090594   \n",
       "2                            0.099924            -0.690133   \n",
       "3                            0.086053            -0.053087   \n",
       "4                            0.281712             0.072129   \n",
       "...                               ...                  ...   \n",
       "109474                       0.334530            -0.077900   \n",
       "109475                       0.204634            -0.801500   \n",
       "109476                       0.109280             0.113676   \n",
       "109477                       0.150946            -0.823428   \n",
       "109478                       0.105744            -0.532602   \n",
       "\n",
       "        G26_fdp_Target Sequence_base  G26_fd_SMILES_base  \\\n",
       "0                           0.036227           -0.081210   \n",
       "1                           0.112054            0.221216   \n",
       "2                          -0.830831           -0.068290   \n",
       "3                          -0.884247           -0.015086   \n",
       "4                          -0.045202            0.035891   \n",
       "...                              ...                 ...   \n",
       "109474                      0.220246           -0.007154   \n",
       "109475                     -0.746084           -0.066957   \n",
       "109476                      0.063588            0.246735   \n",
       "109477                     -0.814621           -0.047486   \n",
       "109478                     -0.892080           -0.009238   \n",
       "\n",
       "        G26_fd_Target Sequence_base  G26_std_SMILES_dist  \\\n",
       "0                          0.002251            -1.406308   \n",
       "1                          0.108463             7.526585   \n",
       "2                         -0.069587            -0.813822   \n",
       "3                         -0.088834            -0.071465   \n",
       "4                         -0.012556             1.872736   \n",
       "...                             ...                  ...   \n",
       "109474                     0.070379             0.495341   \n",
       "109475                    -0.064771            -0.722769   \n",
       "109476                     0.029709             4.253889   \n",
       "109477                    -0.063337            -0.905470   \n",
       "109478                    -0.159431            -0.199843   \n",
       "\n",
       "        G26_std_Target Sequence_dist  \n",
       "0                           0.281301  \n",
       "1                           2.646602  \n",
       "2                          -1.115077  \n",
       "3                          -2.502975  \n",
       "4                           0.285750  \n",
       "...                              ...  \n",
       "109474                      1.372400  \n",
       "109475                     -1.269441  \n",
       "109476                      1.786510  \n",
       "109477                     -1.163646  \n",
       "109478                     -2.234073  \n",
       "\n",
       "[109479 rows x 14 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:, :14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7KZ7TpNoXtlg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bwubete/opt/anaconda3/envs/py38/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:29:35] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1631904775127/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, min_split_loss=0, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=1000, n_jobs=16,\n",
       "              num_parallel_tree=1, random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=0.25, seed=42, subsample=0.8, tree_method='hist',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params = {'learning_rate': 0.1,\n",
    " 'n_estimators':1000,\n",
    " 'max_depth':4,\n",
    " 'min_child_weight':1,\n",
    " 'min_split_loss':0, #gamma\n",
    " 'subsample':0.8,\n",
    " 'colsample_bytree':0.8,\n",
    " 'objective': 'binary:logistic',\n",
    " 'scale_pos_weight': 0.25,\n",
    " 'seed':42,\n",
    " 'tree_method':'hist'}\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "xg_model = XGBClassifier(**default_params)\n",
    "xg_model.fit(train.iloc[:, :336], train.iloc[:, 337].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=0.434 auc=0.733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'P-R Curve on Test Set')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_curve, auc, accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "probs = xg_model.predict_proba(test.iloc[:, :336])[:,1]\n",
    "predictions = xg_model.predict(test.iloc[:, :336])\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(test.iloc[:, 337].astype(int), probs)\n",
    "\n",
    "f1, auc_score = f1_score(test.iloc[:, 337].astype(int), predictions), auc(recall, precision)\n",
    "\n",
    "print('f1=%.3f auc=%.3f' % (f1, auc_score))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim(0,1.05)\n",
    "plt.title('P-R Curve on Test Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "default_params = {\n",
    " 'n_estimators':1000,\n",
    " 'max_depth':10,\n",
    " 'random_state':42}\n",
    "clf = RandomForestClassifier(**default_params)\n",
    "clf.fit(train.iloc[:, :336], train.iloc[:, 337].astype(int))\n",
    "probs = clf.predict_proba(test.iloc[:, :336])[:,1]\n",
    "predictions = clf.predict(test.iloc[:, :336])\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(test.iloc[:, 337].astype(int), probs)\n",
    "\n",
    "f1, auc_score = f1_score(test.iloc[:, 337].astype(int), predictions), auc(recall, precision)\n",
    "\n",
    "print('f1=%.3f auc=%.3f' % (f1, auc_score))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim(0,1.05)\n",
    "plt.title('P-R Curve on Test Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "default_params = {\n",
    " 'learning_rate': 0.1,\n",
    " 'n_estimators': 1000,\n",
    " 'random_state': 42,\n",
    "}\n",
    "clf = AdaBoostClassifier(**default_params)\n",
    "clf.fit(train.iloc[:, :336], train.iloc[:, 337].astype(int))\n",
    "probs = clf.predict_proba(test.iloc[:, :336])[:,1]\n",
    "predictions = clf.predict(test.iloc[:, :336])\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(test.iloc[:, 337].astype(int), probs)\n",
    "\n",
    "f1, auc_score = f1_score(test.iloc[:, 337].astype(int), predictions), auc(recall, precision)\n",
    "\n",
    "print('f1=%.3f auc=%.3f' % (f1, auc_score))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim(0,1.05)\n",
    "plt.title('P-R Curve on Test Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([64743, 17366]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train['Label'].astype(int).to_numpy(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "selector = SelectKBest(f_classif, k=100)\n",
    "X_new = selector.fit_transform(train.iloc[:, :336], train.iloc[:, 337].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans, KMeans, SpectralClustering\n",
    "k_means = KMeans(init='k-means++', n_clusters=5, n_init=10)\n",
    "k_means.fit(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4], dtype=int32),\n",
       " array([ 4028, 30464, 31293,  2094, 14230]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(k_means.labels_, return_counts=True)\n",
    "#selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, ..., 0, 2, 1], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(np.array([list(range(5))]).T)\n",
    "enc.transform(np.array([k_means.predict(X_new)]).T).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 3, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 3, 2), random_state=1)\n",
    "clf.fit(enc.transform(np.array([k_means.predict(X_new)]).T).toarray(), train.iloc[:, 337].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bwubete/opt/anaconda3/envs/py38/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:54:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1631904775127/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "f1=0.000 auc=0.351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'P-R Curve on Test Set')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "yTest = test.iloc[:, 337].astype(int)\n",
    "xTest = enc.transform(np.array([k_means.predict(test.iloc[:, selector.get_support(indices=True)].to_numpy())]).T).toarray() \n",
    "\n",
    "\n",
    "default_params = {'learning_rate': 0.1,\n",
    " 'n_estimators':1000,\n",
    " 'max_depth':4,\n",
    " 'min_child_weight':1,\n",
    " 'min_split_loss':0, #gamma\n",
    " 'subsample':0.8,\n",
    " 'colsample_bytree':0.8,\n",
    " 'objective': 'binary:logistic',\n",
    " 'scale_pos_weight': 0.25,\n",
    " 'seed':42,\n",
    " 'tree_method':'hist'}\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "xg_model = XGBClassifier(**default_params)\n",
    "xg_model.fit(enc.transform(np.array([k_means.predict(X_new)]).T).toarray(), train.iloc[:, 337].astype(int))\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, auc, accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "probs = xg_model.predict_proba(xTest)[:,1]\n",
    "predictions = xg_model.predict(xTest)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(yTest, probs)\n",
    "\n",
    "f1, auc_score = f1_score(yTest, predictions), auc(recall, precision)\n",
    "\n",
    "print('f1=%.3f auc=%.3f' % (f1, auc_score))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim(0,1.05)\n",
    "plt.title('P-R Curve on Test Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  10,  13,  14,  15,  16,  18,  20,  22,  23,  24,  25,  26,\n",
       "        27,  42,  43,  48,  49,  50,  52,  54,  56,  57,  58,  60,  62,\n",
       "        64,  65,  66,  67,  68,  69,  70,  71,  76,  78, 140, 141, 142,\n",
       "       146, 148, 149, 150, 151, 152, 153, 196, 203, 210, 211, 218, 220,\n",
       "       222, 224, 225, 232, 238, 239, 244, 246, 248, 250, 252, 253, 258,\n",
       "       259, 260, 262, 264, 266, 267, 268, 274, 275, 276, 278, 279, 280,\n",
       "       281, 286, 287, 288, 290, 292, 295, 300, 308, 309, 314, 315, 316,\n",
       "       318, 320, 321, 322, 323, 328, 330, 332, 334])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7222871757398611\n",
      "Senstivity/Recall: 0.3485921575401624\n",
      "Specificity: 0.8225290765024791\n",
      "Percision: 0.3450752393980848\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "y_pred = k_means.predict(test.iloc[:, selector.get_support(indices=True)].to_numpy())#cross_val_predict(k_means, test.iloc[:, :336], test.iloc[:, 337].astype(int), cv=5)\n",
    "cm = confusion_matrix(test.iloc[:, 337].astype(int), y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print(f\"Accuracy: {(TP+TN) / (TP+TN+FN+FP)}\")\n",
    "print(f\"Senstivity/Recall: {TP / (TP+FN)}\")\n",
    "print(f\"Specificity: {TN / (TN+FP)}\")\n",
    "print(f\"Percision: {TP / (TP+FP)}\")\n",
    "#generate_roc_p_recall_curve(k_means, test.iloc[:, :336], test.iloc[:, 337].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ev79Kim8cJva"
   },
   "outputs": [],
   "source": [
    "def load_data(batch_size):\n",
    "  \"\"\"Load the dataset into memory.\"\"\"\n",
    "  data = pd.read_csv('train_data.csv') # load original dataset \n",
    "\n",
    "  train, test = sklearn.model_selection.train_test_split(data, test_size=.25, random_state=42, shuffle=True, stratify=data['Label'])\n",
    "\n",
    "  return (tf.data.Dataset.from_tensor_slices((train.copy().drop('Label', axis = 1), train.pop('Label').astype(int))).batch(batch_size),\n",
    "          tf.data.Dataset.from_tensor_slices((test.copy().drop('Label', axis = 1), test.pop('Label').astype(int))).batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gmGB6LCi5dWO"
   },
   "outputs": [],
   "source": [
    "# Defined in file: ./chapter_linear-networks/softmax-regression-scratch.md\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):\n",
    "    \"\"\"Train a model (defined in Chapter 3).\"\"\"\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1.5],\n",
    "                        legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = d2l.train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        test_acc = d2l.evaluate_accuracy(net, test_iter)\n",
    "        print(f'train_metrics: {train_metrics}. test_acc: {test_acc}')\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aoX9qhz_mvMo"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import losses_utils\n",
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(336),\n",
    "    tf.keras.layers.Dense(24),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "batch_size, lr, num_epochs = 255, 0.1, 10\n",
    "loss = tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=False, label_smoothing=0.0, axis=-1,\n",
    "    reduction=losses_utils.ReductionV2.AUTO, name='binary_crossentropy'\n",
    ")\n",
    "trainer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "train_iter, test_iter = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "nbSrzPHh52eK",
    "outputId": "d85e3a4e-a03f-40b4-f591-55d44d0cd02a"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "3.2941621300637243",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fs/sck0dtnd1b9_0kystds1j1180000gp/T/ipykernel_54508/1065474249.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ch3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/fs/sck0dtnd1b9_0kystds1j1180000gp/T/ipykernel_54508/2870942878.py\u001b[0m in \u001b[0;36mtrain_ch3\u001b[0;34m(net, train_iter, test_iter, loss, num_epochs, updater)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0manimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 3.2941621300637243"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg height=\"184.455469pt\" version=\"1.1\" viewBox=\"0 0 245.328125 184.455469\" width=\"245.328125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-11-22T22:20:33.466236</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 184.455469 \n",
       "L 245.328125 184.455469 \n",
       "L 245.328125 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 36.465625 146.899219 \n",
       "L 231.765625 146.899219 \n",
       "L 231.765625 10.999219 \n",
       "L 36.465625 10.999219 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 58.165625 146.899219 \n",
       "L 58.165625 10.999219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m5dd16d31e0\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.165625\" xlink:href=\"#m5dd16d31e0\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_3\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 -3.5 \n",
       "\" id=\"md076148b5c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.165625\" xlink:href=\"#md076148b5c\" y=\"10.999219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(54.984375 161.497656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 101.565625 146.899219 \n",
       "L 101.565625 10.999219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"101.565625\" xlink:href=\"#m5dd16d31e0\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"101.565625\" xlink:href=\"#md076148b5c\" y=\"10.999219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(98.384375 161.497656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 144.965625 146.899219 \n",
       "L 144.965625 10.999219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"144.965625\" xlink:href=\"#m5dd16d31e0\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"144.965625\" xlink:href=\"#md076148b5c\" y=\"10.999219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(141.784375 161.497656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 188.365625 146.899219 \n",
       "L 188.365625 10.999219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"188.365625\" xlink:href=\"#m5dd16d31e0\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"188.365625\" xlink:href=\"#md076148b5c\" y=\"10.999219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(185.184375 161.497656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 231.765625 146.899219 \n",
       "L 231.765625 10.999219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"231.765625\" xlink:href=\"#m5dd16d31e0\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_15\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"231.765625\" xlink:href=\"#md076148b5c\" y=\"10.999219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(225.403125 161.497656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n",
       "        <path d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(118.8875 175.175781)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\n",
       "       <path d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" id=\"DejaVuSans-70\" transform=\"scale(0.015625)\"/>\n",
       "       <path d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\n",
       "       <path d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" id=\"DejaVuSans-63\" transform=\"scale(0.015625)\"/>\n",
       "       <path d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" id=\"DejaVuSans-68\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"125\" xlink:href=\"#DejaVuSans-6f\"/>\n",
       "      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_16\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 36.465625 146.899219 \n",
       "L 231.765625 146.899219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_17\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m2d22ca3fb6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2d22ca3fb6\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 3.5 0 \n",
       "\" id=\"m7f22a43ad0\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"231.765625\" xlink:href=\"#m7f22a43ad0\" y=\"146.899219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.00 -->\n",
       "      <g transform=\"translate(7.2 150.698437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 36.465625 124.249219 \n",
       "L 231.765625 124.249219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2d22ca3fb6\" y=\"124.249219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_21\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"231.765625\" xlink:href=\"#m7f22a43ad0\" y=\"124.249219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.25 -->\n",
       "      <g transform=\"translate(7.2 128.048437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_22\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 36.465625 101.599219 \n",
       "L 231.765625 101.599219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_23\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2d22ca3fb6\" y=\"101.599219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"231.765625\" xlink:href=\"#m7f22a43ad0\" y=\"101.599219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.50 -->\n",
       "      <g transform=\"translate(7.2 105.398437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 36.465625 78.949219 \n",
       "L 231.765625 78.949219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_26\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2d22ca3fb6\" y=\"78.949219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_27\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"231.765625\" xlink:href=\"#m7f22a43ad0\" y=\"78.949219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.75 -->\n",
       "      <g transform=\"translate(7.2 82.748437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 525 4666 \n",
       "L 3525 4666 \n",
       "L 3525 4397 \n",
       "L 1831 0 \n",
       "L 1172 0 \n",
       "L 2766 4134 \n",
       "L 525 4134 \n",
       "L 525 4666 \n",
       "z\n",
       "\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-37\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_28\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 36.465625 56.299219 \n",
       "L 231.765625 56.299219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_29\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2d22ca3fb6\" y=\"56.299219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_30\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"231.765625\" xlink:href=\"#m7f22a43ad0\" y=\"56.299219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1.00 -->\n",
       "      <g transform=\"translate(7.2 60.098437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_31\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 36.465625 33.649219 \n",
       "L 231.765625 33.649219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_32\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2d22ca3fb6\" y=\"33.649219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_33\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"231.765625\" xlink:href=\"#m7f22a43ad0\" y=\"33.649219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.25 -->\n",
       "      <g transform=\"translate(7.2 37.448437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_34\">\n",
       "      <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 36.465625 10.999219 \n",
       "L 231.765625 10.999219 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_35\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m2d22ca3fb6\" y=\"10.999219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"line2d_36\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"231.765625\" xlink:href=\"#m7f22a43ad0\" y=\"10.999219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 1.50 -->\n",
       "      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_37\">\n",
       "    <path clip-path=\"url(#p827fcd9ac8)\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_38\">\n",
       "    <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 36.465625 142.425989 \n",
       "L 58.165625 146.899219 \n",
       "L 79.865625 146.899219 \n",
       "L 101.565625 146.899219 \n",
       "L 123.265625 146.899219 \n",
       "L 144.965625 146.899219 \n",
       "L 166.665625 146.899219 \n",
       "L 188.365625 146.899219 \n",
       "L 210.065625 146.899219 \n",
       "L 231.765625 146.899219 \n",
       "\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_39\">\n",
       "    <path clip-path=\"url(#p827fcd9ac8)\" d=\"M 36.465625 146.899219 \n",
       "L 58.165625 146.899219 \n",
       "L 79.865625 146.899219 \n",
       "L 101.565625 146.899219 \n",
       "L 123.265625 146.899219 \n",
       "L 144.965625 146.899219 \n",
       "L 166.665625 146.899219 \n",
       "L 188.365625 146.899219 \n",
       "L 210.065625 146.899219 \n",
       "L 231.765625 146.899219 \n",
       "\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 36.465625 146.899219 \n",
       "L 36.465625 10.999219 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 231.765625 146.899219 \n",
       "L 231.765625 10.999219 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 36.465625 146.899219 \n",
       "L 231.765625 146.899219 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 36.465625 10.999219 \n",
       "L 231.765625 10.999219 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 146.996875 63.033594 \n",
       "L 224.765625 63.033594 \n",
       "Q 226.765625 63.033594 226.765625 61.033594 \n",
       "L 226.765625 17.999219 \n",
       "Q 226.765625 15.999219 224.765625 15.999219 \n",
       "L 146.996875 15.999219 \n",
       "Q 144.996875 15.999219 144.996875 17.999219 \n",
       "L 144.996875 61.033594 \n",
       "Q 144.996875 63.033594 146.996875 63.033594 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_40\">\n",
       "     <path d=\"M 148.996875 24.097656 \n",
       "L 168.996875 24.097656 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_41\"/>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- train loss -->\n",
       "     <g transform=\"translate(176.996875 27.597656)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\n",
       "       <path d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\n",
       "       <path d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\n",
       "       <path d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\n",
       "       <path d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" id=\"DejaVuSans-6e\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\n",
       "       <path d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-6e\"/>\n",
       "      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-20\"/>\n",
       "      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-6c\"/>\n",
       "      <use x=\"292.333984\" xlink:href=\"#DejaVuSans-6f\"/>\n",
       "      <use x=\"353.515625\" xlink:href=\"#DejaVuSans-73\"/>\n",
       "      <use x=\"405.615234\" xlink:href=\"#DejaVuSans-73\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_42\">\n",
       "     <path d=\"M 148.996875 38.775781 \n",
       "L 168.996875 38.775781 \n",
       "\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_43\"/>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- train acc -->\n",
       "     <g transform=\"translate(176.996875 42.275781)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-6e\"/>\n",
       "      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-20\"/>\n",
       "      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"325.830078\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"380.810547\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_44\">\n",
       "     <path d=\"M 148.996875 53.453906 \n",
       "L 168.996875 53.453906 \n",
       "\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_45\"/>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- test acc -->\n",
       "     <g transform=\"translate(176.996875 56.953906)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-73\"/>\n",
       "      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-20\"/>\n",
       "      <use x=\"223.828125\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"285.107422\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"340.087891\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p827fcd9ac8\">\n",
       "   <rect height=\"135.9\" width=\"195.3\" x=\"36.465625\" y=\"10.999219\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G26</th>\n",
       "      <th>G26_Target Sequence_in_SMILES_perc</th>\n",
       "      <th>G26_SMILES_in_Target Sequence_perc</th>\n",
       "      <th>G26_ARRO</th>\n",
       "      <th>G26_SMILES_base</th>\n",
       "      <th>G26_SMILES_base_perc</th>\n",
       "      <th>G26_Target Sequence_base</th>\n",
       "      <th>G26_Target Sequence_base_perc</th>\n",
       "      <th>G26_fdp_SMILES_base</th>\n",
       "      <th>G26_fdp_Target Sequence_base</th>\n",
       "      <th>...</th>\n",
       "      <th>G10_Target Sequence_base</th>\n",
       "      <th>G10_Target Sequence_base_perc</th>\n",
       "      <th>G10_fdp_SMILES_base</th>\n",
       "      <th>G10_fdp_Target Sequence_base</th>\n",
       "      <th>G10_fd_SMILES_base</th>\n",
       "      <th>G10_fd_Target Sequence_base</th>\n",
       "      <th>G10_std_SMILES_dist</th>\n",
       "      <th>G10_std_Target Sequence_dist</th>\n",
       "      <th>KIBA</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.073946</td>\n",
       "      <td>0.954991</td>\n",
       "      <td>0.062554</td>\n",
       "      <td>16.739510</td>\n",
       "      <td>5.522422</td>\n",
       "      <td>0.105597</td>\n",
       "      <td>5.062549</td>\n",
       "      <td>0.098782</td>\n",
       "      <td>-0.849394</td>\n",
       "      <td>0.036227</td>\n",
       "      <td>...</td>\n",
       "      <td>5.645625</td>\n",
       "      <td>0.120050</td>\n",
       "      <td>-0.024235</td>\n",
       "      <td>-0.640176</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>-0.058854</td>\n",
       "      <td>0.538344</td>\n",
       "      <td>-0.688681</td>\n",
       "      <td>11.900001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.826617</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>60569.338400</td>\n",
       "      <td>5.590014</td>\n",
       "      <td>0.091748</td>\n",
       "      <td>6.158633</td>\n",
       "      <td>0.126360</td>\n",
       "      <td>0.090594</td>\n",
       "      <td>0.112054</td>\n",
       "      <td>...</td>\n",
       "      <td>5.589494</td>\n",
       "      <td>0.122443</td>\n",
       "      <td>-0.261973</td>\n",
       "      <td>-0.644310</td>\n",
       "      <td>-0.019836</td>\n",
       "      <td>-0.060652</td>\n",
       "      <td>0.032666</td>\n",
       "      <td>-0.720316</td>\n",
       "      <td>11.699999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.177106</td>\n",
       "      <td>0.818811</td>\n",
       "      <td>0.930755</td>\n",
       "      <td>1.312142</td>\n",
       "      <td>5.556566</td>\n",
       "      <td>0.128679</td>\n",
       "      <td>5.564309</td>\n",
       "      <td>0.099924</td>\n",
       "      <td>-0.690133</td>\n",
       "      <td>-0.830831</td>\n",
       "      <td>...</td>\n",
       "      <td>5.549520</td>\n",
       "      <td>0.117385</td>\n",
       "      <td>-0.346797</td>\n",
       "      <td>-0.768549</td>\n",
       "      <td>-0.024956</td>\n",
       "      <td>-0.071758</td>\n",
       "      <td>-0.112331</td>\n",
       "      <td>-1.020784</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.179001</td>\n",
       "      <td>0.183497</td>\n",
       "      <td>0.970300</td>\n",
       "      <td>5.616494</td>\n",
       "      <td>5.258327</td>\n",
       "      <td>0.130410</td>\n",
       "      <td>5.683928</td>\n",
       "      <td>0.086053</td>\n",
       "      <td>-0.053087</td>\n",
       "      <td>-0.884247</td>\n",
       "      <td>...</td>\n",
       "      <td>5.784208</td>\n",
       "      <td>0.118799</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>-0.755603</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>-0.067145</td>\n",
       "      <td>1.285098</td>\n",
       "      <td>-0.965758</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.822746</td>\n",
       "      <td>0.029429</td>\n",
       "      <td>0.326915</td>\n",
       "      <td>103.942684</td>\n",
       "      <td>5.621003</td>\n",
       "      <td>0.101558</td>\n",
       "      <td>5.896788</td>\n",
       "      <td>0.281712</td>\n",
       "      <td>0.072129</td>\n",
       "      <td>-0.045202</td>\n",
       "      <td>...</td>\n",
       "      <td>5.631512</td>\n",
       "      <td>0.120159</td>\n",
       "      <td>-0.181766</td>\n",
       "      <td>-0.524913</td>\n",
       "      <td>-0.015458</td>\n",
       "      <td>-0.051385</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>-0.458659</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109474</th>\n",
       "      <td>5.706429</td>\n",
       "      <td>0.185805</td>\n",
       "      <td>0.114284</td>\n",
       "      <td>47.093032</td>\n",
       "      <td>5.747547</td>\n",
       "      <td>0.107905</td>\n",
       "      <td>5.331223</td>\n",
       "      <td>0.334530</td>\n",
       "      <td>-0.077900</td>\n",
       "      <td>0.220246</td>\n",
       "      <td>...</td>\n",
       "      <td>5.698384</td>\n",
       "      <td>0.118799</td>\n",
       "      <td>0.011541</td>\n",
       "      <td>-0.447291</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>-0.045292</td>\n",
       "      <td>0.756821</td>\n",
       "      <td>-0.292137</td>\n",
       "      <td>11.900001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109475</th>\n",
       "      <td>5.091452</td>\n",
       "      <td>0.922677</td>\n",
       "      <td>0.950718</td>\n",
       "      <td>1.139983</td>\n",
       "      <td>5.456824</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>5.444070</td>\n",
       "      <td>0.204634</td>\n",
       "      <td>-0.801500</td>\n",
       "      <td>-0.746084</td>\n",
       "      <td>...</td>\n",
       "      <td>5.560424</td>\n",
       "      <td>0.116188</td>\n",
       "      <td>-0.409694</td>\n",
       "      <td>-0.776436</td>\n",
       "      <td>-0.027857</td>\n",
       "      <td>-0.072332</td>\n",
       "      <td>-0.220516</td>\n",
       "      <td>-1.035303</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109476</th>\n",
       "      <td>6.546598</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.045692</td>\n",
       "      <td>1354.569388</td>\n",
       "      <td>5.250993</td>\n",
       "      <td>0.129833</td>\n",
       "      <td>6.357718</td>\n",
       "      <td>0.109280</td>\n",
       "      <td>0.113676</td>\n",
       "      <td>0.063588</td>\n",
       "      <td>...</td>\n",
       "      <td>6.345158</td>\n",
       "      <td>0.116732</td>\n",
       "      <td>0.112522</td>\n",
       "      <td>-0.822454</td>\n",
       "      <td>0.119631</td>\n",
       "      <td>-0.069714</td>\n",
       "      <td>4.592568</td>\n",
       "      <td>-1.243952</td>\n",
       "      <td>11.699999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109477</th>\n",
       "      <td>5.049065</td>\n",
       "      <td>0.941720</td>\n",
       "      <td>0.965568</td>\n",
       "      <td>1.099754</td>\n",
       "      <td>5.300778</td>\n",
       "      <td>0.118292</td>\n",
       "      <td>5.390484</td>\n",
       "      <td>0.150946</td>\n",
       "      <td>-0.823428</td>\n",
       "      <td>-0.814621</td>\n",
       "      <td>...</td>\n",
       "      <td>5.543945</td>\n",
       "      <td>0.116678</td>\n",
       "      <td>-0.590883</td>\n",
       "      <td>-0.697346</td>\n",
       "      <td>-0.035138</td>\n",
       "      <td>-0.064793</td>\n",
       "      <td>-0.470926</td>\n",
       "      <td>-0.808453</td>\n",
       "      <td>11.900001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109478</th>\n",
       "      <td>5.041841</td>\n",
       "      <td>0.635314</td>\n",
       "      <td>0.997824</td>\n",
       "      <td>1.577456</td>\n",
       "      <td>5.088853</td>\n",
       "      <td>0.102712</td>\n",
       "      <td>5.998127</td>\n",
       "      <td>0.105744</td>\n",
       "      <td>-0.532602</td>\n",
       "      <td>-0.892080</td>\n",
       "      <td>...</td>\n",
       "      <td>5.715002</td>\n",
       "      <td>0.115753</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>-0.601610</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>-0.056031</td>\n",
       "      <td>0.935794</td>\n",
       "      <td>-0.592901</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109479 rows × 338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             G26  G26_Target Sequence_in_SMILES_perc  \\\n",
       "0       5.073946                            0.954991   \n",
       "1       6.826617                            0.001154   \n",
       "2       5.177106                            0.818811   \n",
       "3       5.179001                            0.183497   \n",
       "4       5.822746                            0.029429   \n",
       "...          ...                                 ...   \n",
       "109474  5.706429                            0.185805   \n",
       "109475  5.091452                            0.922677   \n",
       "109476  6.546598                            0.016157   \n",
       "109477  5.049065                            0.941720   \n",
       "109478  5.041841                            0.635314   \n",
       "\n",
       "        G26_SMILES_in_Target Sequence_perc      G26_ARRO  G26_SMILES_base  \\\n",
       "0                                 0.062554     16.739510         5.522422   \n",
       "1                                 0.014306  60569.338400         5.590014   \n",
       "2                                 0.930755      1.312142         5.556566   \n",
       "3                                 0.970300      5.616494         5.258327   \n",
       "4                                 0.326915    103.942684         5.621003   \n",
       "...                                    ...           ...              ...   \n",
       "109474                            0.114284     47.093032         5.747547   \n",
       "109475                            0.950718      1.139983         5.456824   \n",
       "109476                            0.045692   1354.569388         5.250993   \n",
       "109477                            0.965568      1.099754         5.300778   \n",
       "109478                            0.997824      1.577456         5.088853   \n",
       "\n",
       "        G26_SMILES_base_perc  G26_Target Sequence_base  \\\n",
       "0                   0.105597                  5.062549   \n",
       "1                   0.091748                  6.158633   \n",
       "2                   0.128679                  5.564309   \n",
       "3                   0.130410                  5.683928   \n",
       "4                   0.101558                  5.896788   \n",
       "...                      ...                       ...   \n",
       "109474              0.107905                  5.331223   \n",
       "109475              0.121177                  5.444070   \n",
       "109476              0.129833                  6.357718   \n",
       "109477              0.118292                  5.390484   \n",
       "109478              0.102712                  5.998127   \n",
       "\n",
       "        G26_Target Sequence_base_perc  G26_fdp_SMILES_base  \\\n",
       "0                            0.098782            -0.849394   \n",
       "1                            0.126360             0.090594   \n",
       "2                            0.099924            -0.690133   \n",
       "3                            0.086053            -0.053087   \n",
       "4                            0.281712             0.072129   \n",
       "...                               ...                  ...   \n",
       "109474                       0.334530            -0.077900   \n",
       "109475                       0.204634            -0.801500   \n",
       "109476                       0.109280             0.113676   \n",
       "109477                       0.150946            -0.823428   \n",
       "109478                       0.105744            -0.532602   \n",
       "\n",
       "        G26_fdp_Target Sequence_base  ...  G10_Target Sequence_base  \\\n",
       "0                           0.036227  ...                  5.645625   \n",
       "1                           0.112054  ...                  5.589494   \n",
       "2                          -0.830831  ...                  5.549520   \n",
       "3                          -0.884247  ...                  5.784208   \n",
       "4                          -0.045202  ...                  5.631512   \n",
       "...                              ...  ...                       ...   \n",
       "109474                      0.220246  ...                  5.698384   \n",
       "109475                     -0.746084  ...                  5.560424   \n",
       "109476                      0.063588  ...                  6.345158   \n",
       "109477                     -0.814621  ...                  5.543945   \n",
       "109478                     -0.892080  ...                  5.715002   \n",
       "\n",
       "        G10_Target Sequence_base_perc  G10_fdp_SMILES_base  \\\n",
       "0                            0.120050            -0.024235   \n",
       "1                            0.122443            -0.261973   \n",
       "2                            0.117385            -0.346797   \n",
       "3                            0.118799             0.045586   \n",
       "4                            0.120159            -0.181766   \n",
       "...                               ...                  ...   \n",
       "109474                       0.118799             0.011541   \n",
       "109475                       0.116188            -0.409694   \n",
       "109476                       0.116732             0.112522   \n",
       "109477                       0.116678            -0.590883   \n",
       "109478                       0.115753             0.025389   \n",
       "\n",
       "        G10_fdp_Target Sequence_base  G10_fd_SMILES_base  \\\n",
       "0                          -0.640176           -0.004603   \n",
       "1                          -0.644310           -0.019836   \n",
       "2                          -0.768549           -0.024956   \n",
       "3                          -0.755603            0.018378   \n",
       "4                          -0.524913           -0.015458   \n",
       "...                              ...                 ...   \n",
       "109474                     -0.447291            0.002877   \n",
       "109475                     -0.776436           -0.027857   \n",
       "109476                     -0.822454            0.119631   \n",
       "109477                     -0.697346           -0.035138   \n",
       "109478                     -0.601610            0.007480   \n",
       "\n",
       "        G10_fd_Target Sequence_base  G10_std_SMILES_dist  \\\n",
       "0                         -0.058854             0.538344   \n",
       "1                         -0.060652             0.032666   \n",
       "2                         -0.071758            -0.112331   \n",
       "3                         -0.067145             1.285098   \n",
       "4                         -0.051385             0.119600   \n",
       "...                             ...                  ...   \n",
       "109474                    -0.045292             0.756821   \n",
       "109475                    -0.072332            -0.220516   \n",
       "109476                    -0.069714             4.592568   \n",
       "109477                    -0.064793            -0.470926   \n",
       "109478                    -0.056031             0.935794   \n",
       "\n",
       "        G10_std_Target Sequence_dist       KIBA  Label  \n",
       "0                          -0.688681  11.900001  False  \n",
       "1                          -0.720316  11.699999  False  \n",
       "2                          -1.020784  11.300000  False  \n",
       "3                          -0.965758  11.800000  False  \n",
       "4                          -0.458659  11.600000  False  \n",
       "...                              ...        ...    ...  \n",
       "109474                     -0.292137  11.900001  False  \n",
       "109475                     -1.035303  11.200000  False  \n",
       "109476                     -1.243952  11.699999  False  \n",
       "109477                     -0.808453  11.900001  False  \n",
       "109478                     -0.592901  11.200000  False  \n",
       "\n",
       "[109479 rows x 338 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c68ead6d76c4ea1bac25c610c2caba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bwubete/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sweetviz/graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report last_features.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "import sweetviz as sv\n",
    "#analyzing the dataset\n",
    "\n",
    "advert_report = sv.analyze(data.iloc[: , 200:339])\n",
    "#display the report\n",
    "\n",
    "advert_report.show_html(filepath='last_features.html',\n",
    "            layout='widescreen', \n",
    "            scale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report first_200_features.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "advert_report.show_html(filepath='first_200_features.html',\n",
    "            layout='widescreen', \n",
    "            scale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pL_xAHNei2r"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "abalone_model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8a5isYagHQa",
    "outputId": "17f15e09-1155-4fdf-aaa4-fdfc8a02ce43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3422/3422 [==============================] - 7s 2ms/step - loss: 1028308736.0000\n",
      "Epoch 2/10\n",
      "3422/3422 [==============================] - 7s 2ms/step - loss: 566532608.0000\n",
      "Epoch 3/10\n",
      "3422/3422 [==============================] - 6s 2ms/step - loss: 631893376.0000\n",
      "Epoch 4/10\n",
      "3422/3422 [==============================] - 6s 2ms/step - loss: 398156672.0000\n",
      "Epoch 5/10\n",
      "3422/3422 [==============================] - 6s 2ms/step - loss: 110368792.0000\n",
      "Epoch 6/10\n",
      "3422/3422 [==============================] - 6s 2ms/step - loss: 26477078.0000\n",
      "Epoch 7/10\n",
      "3422/3422 [==============================] - 6s 2ms/step - loss: 47782264.0000\n",
      "Epoch 8/10\n",
      "3422/3422 [==============================] - 6s 2ms/step - loss: 13180386.0000\n",
      "Epoch 9/10\n",
      "3422/3422 [==============================] - 6s 2ms/step - loss: 14557719.0000\n",
      "Epoch 10/10\n",
      "3422/3422 [==============================] - 7s 2ms/step - loss: 5530712.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f37dd7eef10>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/sck0dtnd1b9_0kystds1j1180000gp/T/ipykernel_52364/1560837991.py:27: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans.fit(df[scols])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fs/sck0dtnd1b9_0kystds1j1180000gp/T/ipykernel_52364/1560837991.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkmeans_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilhouette_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mselected_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mselected_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilhouette_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mlabel_freqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_number_of_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36mcheck_number_of_labels\u001b[0;34m(n_labels, n_samples)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \"\"\"\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         raise ValueError(\"Number of labels is %d. Valid values are 2 \"\n\u001b[0m\u001b[1;32m     35\u001b[0m                          \"to n_samples - 1 (inclusive)\" % n_labels)\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "df = train\n",
    "scaler = StandardScaler()\n",
    "\n",
    "kmeans_kwargs = {\"init\": \"random\",\"n_init\": 20,\"max_iter\": 1000,\"random_state\": 1984}\n",
    "cut_off=0.5\n",
    "maxvars=3\n",
    "kmin=2\n",
    "kmax=8\n",
    "cols=list(df.columns)\n",
    "\n",
    "results_for_each_k=[]\n",
    "vars_for_each_k={}\n",
    "\n",
    "for k in range(kmin,kmax+1):\n",
    "    print(k)\n",
    "    selected_variables=[]\n",
    "    while(len(selected_variables)<maxvars):\n",
    "        results=[]\n",
    "        for col in cols:\n",
    "            scols=[]\n",
    "            scols.extend(selected_variables)\n",
    "            scols.append(col) \n",
    "            kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "            kmeans.fit(df[scols])\n",
    "            results.append(silhouette_score(df[scols], kmeans.predict(df[scols])))\n",
    "        selected_var=cols[np.argmax(results)]\n",
    "        selected_variables.append(selected_var)\n",
    "        cols.remove(selected_var)\n",
    "    results_for_each_k.append(max(results))\n",
    "    vars_for_each_k[k]=selected_variables\n",
    "\n",
    "\n",
    "best_k=np.argmax(results_for_each_k)+kmin\n",
    "#you can also force a value for k\n",
    "#best_k=3\n",
    "selected_variables=vars_for_each_k[best_k]\n",
    "print(best_k)\n",
    "print(selected_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G26', 'G3', 'G25', 'G31', 'G14', 'G2', 'G5', 'G6', 'G7', 'G8', 'G9',\n",
       "       'G12', 'G15', 'G17', 'G21', 'G27', 'G28', 'G32', 'G36', 'G37', 'G38',\n",
       "       'G39', 'G24', 'G10', 'KIBA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns[::14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.feature_selection import SelectKBest, SelectFpr, chi2, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Adopted from reference 2\n",
    "def generate_roc_p_recall_curve(classifier, X, y):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from sklearn import svm, datasets\n",
    "    from sklearn.metrics import auc\n",
    "    from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    # # #############################################################################\n",
    "    # # Data IO and generation\n",
    "\n",
    "    # # Import some data to play with\n",
    "    # iris = datasets.load_iris()\n",
    "    # X = iris.data\n",
    "    # y = iris.target\n",
    "    # X, y = X[y != 2], y[y != 2]\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Add noisy features\n",
    "    random_state = np.random.RandomState(1)\n",
    "    X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "    # #############################################################################\n",
    "    # Classification and ROC analysis\n",
    "\n",
    "    # Run classifier with cross-validation and plot ROC curves\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    #classifier = GaussianNB() #svm.SVC(kernel=\"linear\", probability=True, random_state=random_state)\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "        classifier.fit(X[train], y[train])\n",
    "        viz = plot_roc_curve(classifier, X[test], y[test],\n",
    "                             name='ROC fold {}'.format(i),\n",
    "                             alpha=0.3, lw=1, ax=ax)\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Chance', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "           title=\"Receiver operating characteristic example\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    tprs = []\n",
    "    aucs = [1]\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "        classifier.fit(X[train], y[train])\n",
    "        viz = plot_precision_recall_curve(classifier, X[test], y[test],\n",
    "                             name='ROC fold {}'.format(i),\n",
    "                             alpha=0.3, lw=1, ax=ax)\n",
    "        interp_tpr = np.interp(mean_fpr, viz.precision, viz.recall)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        #aucs.append(viz.roc_auc)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Chance', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "            #label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "           title=\"Percision Recall Curve\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SYSC 5405 - Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
